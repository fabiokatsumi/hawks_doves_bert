{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis_fed.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.3 64-bit (system)"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "interpreter": {
      "hash": "04635d289a519a1410467dd0afb0db42f9184808881ca68b2eb5a687a20a5a94"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNHsK0PMHG48"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjmP2i52Q5RG"
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "_PATH_FOLDER_OUT = './outputs/'\n",
        "_PATH_FOLDER_IN = './inputs/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTfNHU1GHGY6"
      },
      "source": [
        "num_gpus_available = len(tf.config.experimental.list_physical_devices('GPU'))\n",
        "print(\"Num GPUs Available: \", num_gpus_available)\n",
        "assert num_gpus_available > 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KNN_E1tq7NV"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOKfB704rhwK"
      },
      "source": [
        "from transformers import DistilBertTokenizerFast\n",
        "from transformers import TFDistilBertForSequenceClassification\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90pCPPiQsMTq"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "#tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xg265TdvP1Q"
      },
      "source": [
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from transformers import InputExample, InputFeatures\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqQ_7d_EvVK6"
      },
      "source": [
        "def f_load_data():\n",
        "    df = pd.read_csv(_PATH_FOLDER_IN + 'df_agg.csv', sep = ';')\n",
        "    df['short_review'] = df['text']\n",
        "    df['short_review'] = df['short_review'].str.lower()\n",
        "    df = df[[\"short_review\", \"Sentiment\"]]\n",
        "    return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBfSPpnRwSva"
      },
      "source": [
        "\n",
        "def f_save_df(df_save, file_name_in):\n",
        "  df_save.to_csv( _PATH_FOLDER_OUT +  '/' + file_name_in + \".csv\", sep=';', index= False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdpeM_L-ep61"
      },
      "source": [
        "def f_train_model(df_in):\n",
        "    reviews = df_in['short_review'].values.tolist()\n",
        "    labels = df_in['Sentiment'].tolist()\n",
        "    training_sentences, validation_sentences, training_labels, validation_labels = train_test_split(reviews, labels, test_size=.10)\n",
        "    tokenizer([training_sentences[0]], truncation=True,\n",
        "                            padding=True, max_length=1024)\n",
        "    \n",
        "\n",
        "    train_encodings = tokenizer(training_sentences,\n",
        "                            truncation=True,\n",
        "                            padding=True)\n",
        "    val_encodings = tokenizer(validation_sentences,\n",
        "                                truncation=True,\n",
        "                                padding=True)\n",
        "    \n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "        training_labels\n",
        "    ))\n",
        "\n",
        "    val_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "        dict(val_encodings),\n",
        "        validation_labels\n",
        "    ))\n",
        "\n",
        "    #model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
        "    model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5, epsilon=1e-08)\n",
        "    model.compile(optimizer=optimizer, loss=model.compute_loss, metrics=['accuracy'])\n",
        "    model.fit(train_dataset.shuffle(100).batch(2),\n",
        "            epochs=2,\n",
        "            batch_size=2)\n",
        "    # model.fit(train_dataset.shuffle(150).batch(2),\n",
        "    #         epochs=2,\n",
        "    #         batch_size=16,\n",
        "    #         validation_data = val_dataset.shuffle(150).batch(2))\n",
        "    # model.save_pretrained(\"./sentiment\")\n",
        "    # loaded_model = TFDistilBertForSequenceClassification.from_pretrained(\"./sentiment\")\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CopLvY6IC034"
      },
      "source": [
        "def f_get_prediction(model_in, df_in):\n",
        "\n",
        "\n",
        "    text_tmp = df_in['short_review'].iloc[-1]\n",
        "    sent_tmp = df_in['Sentiment'].iloc[-1]\n",
        "    predict_input = tokenizer.encode(text_tmp,\n",
        "                                    truncation=True,\n",
        "                                    padding=True,\n",
        "                                    return_tensors=\"tf\")\n",
        "\n",
        "    tf_output = model_in.predict(predict_input)[0]\n",
        "\n",
        "\n",
        "    tf_prediction = tf.nn.softmax(tf_output, axis=1)\n",
        "    labels = [0,1]\n",
        "    label = tf.argmax(tf_prediction, axis=1)\n",
        "    label = label.numpy()\n",
        "    pred_tmp = labels[label[0]]\n",
        "    print('sentiment: ' + str(sent_tmp) + ' pred: ' + str(pred_tmp))\n",
        "    return pred_tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA2PSKQkC035"
      },
      "source": [
        "df_data = f_load_data()\n",
        "df_agg = df_data.copy()\n",
        "df_agg['Prediction'] = 0\n",
        "index_lst = df_data.index \n",
        "for index_tmp in index_lst[20:]:\n",
        "    print('index_tmp: ' + str(index_tmp) + '/' + str(index_lst[-1]))\n",
        "    df_tmp = df_data[:index_tmp]\n",
        "    df_train = df_data[:index_tmp-1]\n",
        "    model_tmp = f_train_model(df_train)\n",
        "    pred_tmp = f_get_prediction(model_tmp, df_tmp)\n",
        "    df_agg.loc[index_tmp,'Prediction'] = pred_tmp\n",
        "    del model_tmp\n",
        "    tf.keras.backend.clear_session()\n",
        "    filename_out = '_out_' + str(index_tmp)\n",
        "    f_save_df(df_agg, filename_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBoMoLybxkQS"
      },
      "source": [
        "print(df_agg.tail())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKEcJE__x4-z"
      },
      "source": [
        "df_out = df_agg[['Sentiment','Prediction']]\n",
        "df_out.to_csv('df_out.csv', sep = ';', index = False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2Cl7USn71Ae"
      },
      "source": [
        "  filename_out = 'df_out'\n",
        "  f_save_df(df_out, filename_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z3eeXf-C036"
      },
      "source": [
        "confusion_matrix = pd.crosstab(df_out['Sentiment'], df_out['Prediction'], rownames=['Actual'], colnames=['Predicted'], margins = True)\n",
        "print (confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KtAiZPJ581U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s09KuIQEO3po"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}